# Paper-code-review

<img src=https://img.shields.io/badge/%20-Classification-brightgreen> <img src=https://img.shields.io/badge/%20-Object--Detection-lightblue> <img src=https://img.shields.io/badge/%20-Segmentation-green> <img src=https://img.shields.io/badge/%20-XAI-yellowgreen> <img src=https://img.shields.io/badge/%20-Knowledge_distillation-blueviolet> <img src=https://img.shields.io/badge/%20-Modeling-yellow> <img src=https://img.shields.io/badge/%20-Weakly--supervised-blue> <img src=https://img.shields.io/badge/%20-Semi--supervised-lightgrey> <img src=https://img.shields.io/badge/%20-Representation-orange> <img src=https://img.shields.io/badge/%20-Self--supervised-red> <img src=https://img.shields.io/badge/%20-NAS-yellow>

-- **Moving to Notion** --  
[[Table of whole reviews in notion]](https://www.notion.so/2ebb78f709c64d379b3faf277f9bf7e3?v=566189643a944cab996418b7921c3e46)

-- **[200904] Codes of papers were separated into a new organization.** --  
[[organization link]](https://github.com/PaperCodeReview)

## Self-supervised learning
From | Authors | Paper | Institution | url
---- | ---- | ---- | ---- | ----
Arxiv 2020 | J. Grill, F. Strub, F. Altche, C. Tallec, and P. H. Richemond et al. | [Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning](https://arxiv.org/abs/2006.07733) | DeepMind, Imperial College | [code]() [summary](https://www.notion.so/BYOL-Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning-7c87bb790b63414bad626a5892a1e2a6)
Arxiv 2020 | P. Khosla et al. | [Supervised Contrastive Learning](https://arxiv.org/abs/2004.11362) | Google Research | [code](https://github.com/PaperCodeReview/SupCL-TF) [summary](https://www.notion.so/Supervised-Contrastive-Learning-e2140caa8eba4fbca2ebe53a8b78dad7)
CVPR 2020 | K. He et al. | [Momentum Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/abs/1911.05722) | Facebook AI Research (FAIR) | [code](https://github.com/PaperCodeReview/MoCo-TF) [summary](https://www.notion.so/MoCo-v1-Momentum-Contrast-for-Unsupervised-Visual-Representation-Learning-85ebd5422a02428c8bb105bf18e6a836)

## Semi-supervised learning
From | Authors | Paper | Institution | url
---- | ---- | ---- | ---- | ----
Arxiv 2020 | K. Sohn et al. | [FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence](https://arxiv.org/abs/2001.07685) | Google Research | [code]() [summary](https://www.notion.so/FixMatch-FixMatch-Simplifying-Semi-Supervised-Learning-with-Consistency-and-Confidence-a42958190f6c450191365d70cce08961)
CVPR 2020 | D. Wang et al. | [FocalMix: Semi-Supervised Learning for 3D Medical Image Detection](https://arxiv.org/abs/2003.09108) | Peking University, Yizhun Medical AI | [code]() [summary](https://www.notion.so/FocalMix-FocalMix-Semi-Supervised-Learning-for-3D-Medical-Image-Detection-564861b38e2e4daba0b3d313e3d833cd)
NeurIPS 2019 | D. Berthelot et al. | [MixMatch: A Holistic Approach to Semi-Supervised Learning](https://arxiv.org/abs/1905.02249) | Google Research | [code]() [summary](https://www.notion.so/MixMatch-MixMatch-A-Holistic-Approach-to-Semi-Supervised-Learning-6b21345edf934c209ae6d4c44ef7b3e4)
Arxiv 2019 | Q. Xie et al. | [Unsupervised Data Augmentation for Consistency Training](https://arxiv.org/abs/1904.12848) | Google Research, Carnegie Mellon University | [code]() [summary](https://www.notion.so/UDA-Unsupervised-Data-Augmentation-for-Consistency-Training-0c7094b7b53e48618888867fe7a26e3c)

## Knowledge distillation
From | Authors | Paper | Institution | url
---- | ---- | ---- | ---- | ----
CVPR 2020 | S. Yun and J. Park et al. | [Regularizing Class-wise Predictions via Self-knowledge Distillation](https://arxiv.org/abs/2003.13964) | KAIST | [code]() [summary](https://www.notion.so/CS-KD-Regularizing-Class-wise-Prredictions-via-Self-knowledge-Distillation-c4062198e53b4a0a8cd884f28e7a61f5)
CVPR 2020 | Y. Liu et al. | [Search to Distill: Pearls are Everywhere but not the Eyes](https://arxiv.org/abs/1911.09074) | Google AI, Google Brain | [code]() [summary](https://www.notion.so/Search-to-Distill-Pearls-are-Everywhere-but-not-the-Eyes-d8e57509df4244b68ef295273febc262)
ICCV 2019 | L. Zhang et al. | [Be Your Own Teacher: Improve the Performance of Convolutional Neural Networks via Self Distillation](https://arxiv.org/abs/1905.08094) | Tsinghua University | [code]() [summary](https://www.notion.so/Be-Your-Own-Teacher-Improve-the-Performance-of-Convolutional-Neural-Networks-via-Self-Distillation-76e662fdb61a47b5a72376f2e54bf0d5)
ICCV 2019 | B. Heo et al. | [A Comprehensive Overhaul of Feature Distillation](https://arxiv.org/abs/1904.01866) | NAVER Corp, Seoul National University | [code]() [summary]()
NeurIPS 2018 | X. Wang et al. | [KDGAN: Knowledge Distillation with Generative Adversarial Networks](https://papers.nips.cc/paper/7358-kdgan-knowledge-distillation-with-generative-adversarial-networks) | University of Melbourne |  [code]() [summary](https://www.notion.so/KDGAN-KDGAN-Knowledge-Distillation-with-Generative-Adversarial-Networks-852fc740c4ea4423b57a9aa93623c3f5)
ICML 2018 | S. Srinivas et al. | [Knowledge Transfer with Jacobian Matching](https://arxiv.org/abs/1803.00443) | Idiap Research Institute & EPFL |  [code]() [summary](https://www.notion.so/Knowledge-Transfer-with-Jacobian-Matching-40027da0d38943f2a69623aae25b2eed)


## Modeling & NAS
From | Authors | Paper | Institution | url
---- | ---- | ---- | ---- | ----
CVPR 2020 | I. Radosavovic et al. | [Designing Network Design Spaces](https://arxiv.org/abs/2003.13678) | Facebook AI Research (FAIR) | [code](https://github.com/PaperCodeReview/RegNet-TF) [summary](https://www.notion.so/RegNet-Designing-Network-Design-Spaces-455b9494747c46a29b3b6eb9e70425c0)

## XAI (Explainable AI)
From | Authors | Paper | Institution | url
---- | ---- | ---- | ---- | ----
Arxiv 2019 | M. Yang et al. | [BIM: Towards Quantitative Evaluation of Interpretability Methods with Ground Truth](https://deepai.org/publication/bim-towards-quantitative-evaluation-of-interpretability-methods-with-ground-truth) | Google Brain | [code]() [summary]()
NeurIPS 2019 | S. Hooker et al. | [A Benchmark for Interpretability Methods in Deep Neural Networks](https://arxiv.org/abs/1806.10758) | Google Brain |  [code]() [summary](https://www.notion.so/A-Benchmark-for-Interpretability-Methods-in-Deep-Neural-Networks-fc219d4e2d8242509d0f732d17aeb0fe)
ICCV 2019 | B. Kim et al. | [Why are Saliency Maps Noisy? Cause of and Solution to Noisy Saliency Maps](https://arxiv.org/abs/1902.04893) | KAIST | [code]() [summary](https://www.notion.so/Why-are-Saliency-Maps-Noisy-Cause-of-and-Solution-to-Noisy-Saliency-Maps-3a647dbe3ca44f039fc22a9d797b90f1)
NeurIPS 2018 | J. Adebayo et al. | [Sanity Checks for Saliency Maps](https://arxiv.org/abs/1810.03292) | Google Brain |  [code]() [summary](https://www.notion.so/KDGAN-KDGAN-Knowledge-Distillation-with-Generative-Adversarial-Networks-852fc740c4ea4423b57a9aa93623c3f5)
ICML 2018 | J. Seo et al. | [Noise-adding Methods of Saliency Map as Series of Higher Order Partial Derivative](https://arxiv.org/abs/1806.03000) | Satrec Initiative, KAIST |  [code]() [summary](https://www.notion.so/Noise-adding-Methods-of-Saliency-Map-as-Series-of-Higher-Order-Partial-Derivative-e9a82ab4da5048399a51a54d2149526d)
CVPR 2018 | Q. Zhang et al. | [Interpretable Convolutional Neural Networks](https://arxiv.org/abs/1710.00935) | University of California |  [code]() [summary](https://www.notion.so/Interpretable-Convolutional-Neural-Networks-9120d962589a4df999f0a4037da7c8fb)
ICCV 2017 | R. Selvaraju et al. | [Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization](https://arxiv.org/abs/1610.02391) | Georgia Institute of Technology |  [code](https://github.com/rlatjcj/Paper-code-review/tree/master/Grad-CAM) [summary](https://www.notion.so/Grad-CAM-Grad-CAM-Visual-Explanations-from-Deep-Networks-via-Gradient-based-Localization-fe7635d1a23d49df9740c2e38d9d1099)
CVPR 2017 | D. Smilkov et al. | [SmoothGrad: removing noise by adding noise](https://arxiv.org/abs/1706.03825) | Google Inc. |  [code]() [summary](https://www.notion.so/SmoothGrad-SmoothGrad-Removing-Noise-by-Adding-Noise-85bfdf6be9974b56bc24b43c4ebf340e)


## Weakly-supervised learning
From | Authors | Paper | Institution | url
---- | ---- | ---- | ---- | ----
CVPR 2019 | J. Lee et al. | [FickleNet: Weakly and Semi-supervised Semantic Image Segmentation using Stochastic Inference](https://arxiv.org/abs/1902.10421) | Seoul National University | [code](https://github.com/rlatjcj/Paper-code-review/tree/master/FickleNet) [summary](https://www.notion.so/FickleNet-FickleNet-Weakly-and-Semi-supervised-Semantic-Image-Segmentation-using-Stochastic-Infere-888599b7fbb44ee8bb2dd99495e9d4df)

## Representation learning
From | Authors | Paper | Institution | url
---- | ---- | ---- | ---- | ----
CVPR 2019 | J. Deng et al. | [ArcFace: Additive Angular Margin Loss for Deep Face Recognition](https://arxiv.org/abs/1801.07698) | Imperial College London, InsightFace, FaceSoft | [code]() [summary](https://www.notion.so/ArcFace-ArcFace-Additive-Angular-Margin-Loss-for-Deep-Face-Recognition-1b9b623a42c74ad689cd4b8042edb033)

## Attention
From | Authors | Paper | Institution | url
---- | ---- | ---- | ---- | ----
CVPR 2018 | J. Hu et al. | [Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507) | University of Chinese Academy of Sciences |  [code]() [summary](https://www.notion.so/SENet-Squeeze-and-Excitation-Networks-65cec71aca324789bafc172d1e604df1)
ECCV 2018 | S. Woo et al. | [CBAM: Convolutional Block Attention Module](https://arxiv.org/abs/1807.06521) | KAIST |  [code]() [summary](https://www.notion.so/CBAM-CBAM-Convolutional-Block-Attention-Module-85f161eda58a417d84a20e6d4a3ed97c)

## Semantic Segmentation
From | Authors | Paper | Institution | url
---- | ---- | ---- | ---- | ----
ECCV 2018 | L. Chen et al. | [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1802.02611) | Google Inc. |  [code]() [summary](https://www.notion.so/DeepLab-v3-Encoder-Decoder-with-Atrous-Separable-Convolution-for-Semantic-Image-Segmentation-8b41a75358614ffb89734427fd9cfe68)
MIDL 2018 | O. Oktay et al. | [Attention U-Net: Learning Where to Look for the Pancreas](https://arxiv.org/abs/1804.03999) | Imperial College London, Babylon Heath |  [code]() [summary](https://www.notion.so/Attention-U-Net-Attention-U-Net-Learning-Where-to-Look-for-the-Pancreas-0fc9e0987f4f4c4c9ab32670ae210083)
MICCAI 2016 | Ö. Çiçek et al. | [3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation](https://arxiv.org/abs/1606.06650) | University of Freiburg |  [code](https://github.com/rlatjcj/Paper-code-review/tree/master/3D_U-Net) [summary](https://www.notion.so/3D-U-Net-3D-U-Net-Learning-Dense-Volumetric-Segmentation-from-Sparse-Annotation-3606e96c9f7843a0ab64d35af9e3982b)
MICCAI 2015 | Ö. Ronneberger et al. | [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597) | University of Freiburg |  [code](https://github.com/rlatjcj/Paper-code-review/tree/master/U-Net) [summary](https://www.notion.so/U-Net-U-Net-Convolutional-Networks-for-Biomedical-Image-Segmentation-c39ca7c3db184a4989727cc17c9517e2)
CVPR 2015 | J. Long et al. | [Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/abs/1411.4038) | UC Berkeley |  [code]() [summary](https://www.notion.so/FCN-Fully-Convolutional-Networks-for-Semantic-Segmentation-4b8bee55e681449ebe8a1a6a9e3b8fc9)
ICLR 2015 | L. Chen et al. | [Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs](https://arxiv.org/abs/1412.7062) | University of California, Google Inc., and CentraleSupelec |  [code]() [summary](https://www.notion.so/DeepLab-v1-Semantic-Image-Segmentation-with-Deep-Convolutional-Nets-and-Fully-Connected-CRFs-693d8f64cae1433b9cb454c17681c404)

## Object Detection
From | Authors | Paper | Institution | url
---- | ---- | ---- | ---- | ----
Arxiv 2020 | N. Carion et al. | [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872) | Facebook AI Research (FAIR) | [code](https://github.com/PaperCodeReview/DETR-TF) [summary](https://www.notion.so/DETR-End-to-End-Object-Detection-with-Transformers-b5f0a27e7edc4c519c5d16ba99b90be4)

## Classification
From | Authors | Paper | Institution | url
---- | ---- | ---- | ---- | ----
CVPR 2017 | S. Xie et al. | [Aggregated Residual Transformations for Deep Neural Networks](https://openaccess.thecvf.com/content_cvpr_2017/papers/Xie_Aggregated_Residual_Transformations_CVPR_2017_paper.pdf) | UC San Diego |  [code]() [summary](https://www.notion.so/ResNeXt-Aggregated-Residual-Transformations-for-Deep-Neural-Networks-ea2b4ece42c441cea59b09f66738b1eb)
CVPR 2017 | F. Chollet et al. | [Xception: Deep Learning with Depthwise Separable Convolutions](https://arxiv.org/abs/1610.02357) | Google Inc. |  [code]() [summary](https://www.notion.so/Xception-Xception-Deep-Learning-with-Depthwise-Separable-Convolutions-b340a537a1014f95ab6f03858163f8f4)
CVPR 2016 | K. He et al. | [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) | Microsoft Research |  [code]() [summary](https://www.notion.so/ResNet-Deep-Residual-Learning-for-Image-Recognition-a5bd9f094f394707abbdd218d6390a4a)
ICLR 2015 | k. Simonyan et al. | [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) | University of Oxford |  [code](https://github.com/rlatjcj/Paper-code-review/tree/master/VGG) [summary](https://www.notion.so/VGG-Very-Deep-Convolutional-Networks-for-Large-Scale-Image-Recognition-0b8beeeae37847cda5c3a7495e3df5c6)
CVPR 2015 | C. Szegedy et al. | [Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842) | Google Inc. |  [code](https://github.com/rlatjcj/Paper-code-review/tree/master/Inceptionv1) [summary](https://www.notion.so/Inception-v1-Going-Deeper-with-Convolutions-888948cf4272494381b5e1f4a81aeab8)
